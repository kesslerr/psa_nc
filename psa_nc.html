<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.313">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Noise Ceiling Estimation for Representational Similarity Matrices</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>


<script src="psa_nc_files/libs/clipboard/clipboard.min.js"></script>
<script src="psa_nc_files/libs/quarto-html/quarto.js"></script>
<script src="psa_nc_files/libs/quarto-html/popper.min.js"></script>
<script src="psa_nc_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="psa_nc_files/libs/quarto-html/anchor.min.js"></script>
<link href="psa_nc_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="psa_nc_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="psa_nc_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="psa_nc_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="psa_nc_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
</head><body>\usepackage{algorithm2e}
<link href="https://cdn.jsdelivr.net/npm/pseudocode@latest/build/pseudocode.min.css" rel="stylesheet">

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>





<div id="quarto-content" class="page-columns page-rows-contents page-layout-article toc-left">
<div id="quarto-sidebar-toc-left" class="sidebar toc-left">
  <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Contents</h2>
   
  <ul>
  <li><a href="#sec-RSA" id="toc-sec-RSA" class="nav-link active" data-scroll-target="#sec-RSA"><span class="toc-section-number">1</span>  Representational Similarity Analysis (RSA) in a nutshell</a></li>
  <li><a href="#sec-Fisher" id="toc-sec-Fisher" class="nav-link" data-scroll-target="#sec-Fisher"><span class="toc-section-number">2</span>  Excursion: Fisher-r-to-z transformation of correlation coefficients</a></li>
  <li><a href="#sec-NC-RSA" id="toc-sec-NC-RSA" class="nav-link" data-scroll-target="#sec-NC-RSA"><span class="toc-section-number">3</span>  Noise ceiling (NC) for (second stage) RSA</a>
  <ul class="collapse">
  <li><a href="#sec-NCbound-RSA" id="toc-sec-NCbound-RSA" class="nav-link" data-scroll-target="#sec-NCbound-RSA"><span class="toc-section-number">3.1</span>  Boundary procedure (group level inference)</a></li>
  <li><a href="#sec-NCsh-RSA" id="toc-sec-NCsh-RSA" class="nav-link" data-scroll-target="#sec-NCsh-RSA"><span class="toc-section-number">3.2</span>  Split-half approach (single-participant or group level)</a></li>
  </ul></li>
  <li><a href="#sec-NC-PSM" id="toc-sec-NC-PSM" class="nav-link" data-scroll-target="#sec-NC-PSM"><span class="toc-section-number">4</span>  Proposed method: noise ceiling for participant-level RSMs (first stage RSA)</a></li>
  <li><a href="#sec-adj" id="toc-sec-adj" class="nav-link" data-scroll-target="#sec-adj"><span class="toc-section-number">5</span>  Adjustment coefficient</a>
  <ul class="collapse">
  <li><a href="#sec-adj-sb" id="toc-sec-adj-sb" class="nav-link" data-scroll-target="#sec-adj-sb"><span class="toc-section-number">5.1</span>  Spearman-Brown prophecy formula</a></li>
  <li><a href="#sec-adj-emp" id="toc-sec-adj-emp" class="nav-link" data-scroll-target="#sec-adj-emp"><span class="toc-section-number">5.2</span>  Empirical adjustment factor / projection factor</a></li>
  </ul></li>
  <li><a href="#sec-tr" id="toc-sec-tr" class="nav-link" data-scroll-target="#sec-tr"><span class="toc-section-number">6</span>  Time-resolved or concatenated analysis?</a></li>
  <li><a href="#sandbox" id="toc-sandbox" class="nav-link" data-scroll-target="#sandbox"><span class="toc-section-number">7</span>  Sandbox</a></li>
  <li><a href="#references" id="toc-references" class="nav-link" data-scroll-target="#references"><span class="toc-section-number">8</span>  References</a></li>
  </ul>
</nav>
</div>
<div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
</div>
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Noise Ceiling Estimation for Representational Similarity Matrices</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<p>more about Quarto see <a href="https://quarto.org" class="uri">https://quarto.org</a>.</p>
<section id="sec-RSA" class="level1" data-number="1">
<h1 data-number="1"><span class="header-section-number">1</span> Representational Similarity Analysis (RSA) in a nutshell</h1>
<p>The idea is to compare the representational geometry of some neural data with that of a model (<span class="citation" data-cites="kriegeskorte2008">Kriegeskorte, Mur, and Bandettini (<a href="#ref-kriegeskorte2008" role="doc-biblioref">2008</a>)</span>). For example, we stimulate participants with each several repetitions of different visual stimulus categories. In fMRI, we then run a GLM with separate regressors per <span class="math inline">\(k\)</span> category, extract the voxel estimates and put them into a vector <span class="math inline">\(v_k\)</span> of a particular ROI we are interested in. For MEEG, <span class="math inline">\(v_k\)</span> is typically composed of the electrical potentials from the different channels (e.g., electrodes) of an grand average event-related potential (ERP) – an average over several dozens of repetitions or epochs, and the following is then estimated for each time point of the ERP separately (but see <a href="#sec-tr">Section&nbsp;6</a>). We then correlate all <span class="math inline">\(v_k\)</span> with each other to get a <span class="math inline">\(k \times k\)</span> (symmetric) representational similarity matrix (<em>RSM</em>) <span class="math inline">\(D\)</span> (or pattern similarity matrix <em>PSM</em>) representing the neural data (<em>data RSM</em>). For simplicity, and for the sake of this work, this part of the analysis will be named <em>first stage</em> of an <em>RSA</em>.</p>
<p>However, the main interest lies usually on the results of a second stage of an <em>RSA</em>. The lower triangle of <span class="math inline">\(D\)</span> is then (rank) correlated with a <span class="math inline">\(k \times k\)</span> <em>model RSM</em> <span class="math inline">\(M\)</span>. Different <span class="math inline">\(M\)</span> can be compared to each other, e.g.&nbsp;via the magnitude of their correlation with <span class="math inline">\(D\)</span>. For group level inference, <span class="math inline">\(D\)</span> can be averaged (but see <a href="#sec-Fisher">Section&nbsp;2</a>) to <span class="math inline">\(\bar{D}\)</span>, and the result can be (rank) correlated with <span class="math inline">\(M\)</span>.</p>
</section>
<section id="sec-Fisher" class="level1" data-number="2">
<h1 data-number="2"><span class="header-section-number">2</span> Excursion: Fisher-r-to-z transformation of correlation coefficients</h1>
<p>Fisher r-to-z transformation (i.e., <span class="math inline">\(z=arctanh(r)\)</span> or <a href="#eq-r2z">Equation&nbsp;1</a>) for correlation coefficients (including those for noise ceilings) is often not reported in the RSA literature (exceptions, e.g., <span class="citation" data-cites="carlin2017">Carlin and Kriegeskorte (<a href="#ref-carlin2017" role="doc-biblioref">2017</a>)</span> ), and some packages even haven’t implemented it for some reasons (e.g., see discussion <a href="https://github.com/rsagroup/rsatoolbox/issues/370">here</a>).</p>
<p><span id="eq-r2z"><span class="math display">\[
z = \frac{1}{2} ln \left[  \dfrac{1+r}{1-r} \right]
\tag{1}\]</span></span></p>
<p>For steps in which any <span class="math inline">\(r\)</span> needs to be averaged (e.g., across samples, or across subjects), mean <span class="math inline">\(r\)</span> is however biased, especially for <span class="math inline">\(r &gt; 0.5\)</span>. The numeric difference for low <span class="math inline">\(r\)</span> can be treated as neglectable. However, due to the low costs of transformation, I will always implicitly assume that <span class="math inline">\(r\)</span> values are transformed to <span class="math inline">\(z\)</span> for each step that includes e.g., averaging or statistics. After that being done, for the sake of easier interpretability, it is then transformed back using <span class="math inline">\(r = tanh(z)\)</span> or <a href="#eq-z2r">Equation&nbsp;2</a></p>
<p><span id="eq-z2r"><span class="math display">\[
r = \dfrac{e^{2z}-1}{e^{2z}+1}
\tag{2}\]</span></span></p>
</section>
<section id="sec-NC-RSA" class="level1" data-number="3">
<h1 data-number="3"><span class="header-section-number">3</span> Noise ceiling (NC) for (second stage) RSA</h1>
<p>To get an estimate of how well the best possible model could perform, given the noise conditions in the data, noise ceilings (<em>NC</em> or <span class="math inline">\(\nu\)</span>) can be estimated (e.g., <span class="citation" data-cites="lage-castellanos2019">Lage-Castellanos et al. (<a href="#ref-lage-castellanos2019" role="doc-biblioref">2019</a>)</span>). I found versions suitable for RSA. Both of them are applied to estimate NCs for second stage RSA.</p>
<section id="sec-NCbound-RSA" class="level2" data-number="3.1">
<h2 data-number="3.1" class="anchored" data-anchor-id="sec-NCbound-RSA"><span class="header-section-number">3.1</span> Boundary procedure (group level inference)</h2>
<p>The boundary procedure was for example used in <span class="citation" data-cites="kaniuth2022">Kaniuth and Hebart (<a href="#ref-kaniuth2022" role="doc-biblioref">2022</a>)</span> and <span class="citation" data-cites="xie2022">Xie et al. (<a href="#ref-xie2022" role="doc-biblioref">2022</a>)</span> and implemented in <span class="citation" data-cites="nili2014">Nili et al. (<a href="#ref-nili2014" role="doc-biblioref">2014</a>)</span>. The lower <span class="math inline">\(\nu_{lower}\)</span> and upper bound <span class="math inline">\(\nu_{upper}\)</span> of the noise ceiling are estimated separately:</p>
<p>For the upper bound</p>
<ol type="1">
<li>Estimate an average <span class="math inline">\(D\)</span> (<span class="math inline">\(\bar{D}\)</span>) across participants.</li>
<li>Correlate the (lower triangular) of each participants <span class="math inline">\(D_i\)</span> to <span class="math inline">\(\bar{D}\)</span>, and retrieve <span class="math inline">\(\nu_{u,i}\)</span></li>
<li>Average across <span class="math inline">\(\nu_{u,i}\)</span>, to get <span class="math inline">\(\nu_{upper}\)</span></li>
</ol>
<p>This is the upper bound, because it is an overestimated noise ceiling, as <span class="math inline">\(\bar{D}\)</span> and <span class="math inline">\(D_i\)</span> share some information about one participant.</p>
<p>For the lower bound,</p>
<ol type="1">
<li>For each participant, estimate <span class="math inline">\(\bar{D}^{(-i)}\)</span> across participants, which is the average <span class="math inline">\(D\)</span> but without participant <span class="math inline">\(i\)</span>.</li>
<li>Correlate the (lower triangular) of each <span class="math inline">\(D_i\)</span> to <span class="math inline">\(\bar{D}^{(-i)}\)</span>, and retrieve <span class="math inline">\(\nu_{l,i}\)</span></li>
<li>Average across <span class="math inline">\(\nu_{l,i}\)</span>, to get <span class="math inline">\(\nu_{lower}\)</span></li>
</ol>
<p>This is the lower bound, because <span class="math inline">\(\bar{D}^{(-i)}\)</span> does not have as much data as <span class="math inline">\(\bar{D}\)</span> (i.e., participant <span class="math inline">\(i\)</span>). Typically, <span class="math inline">\(\nu_l\)</span> and <span class="math inline">\(\nu_u\)</span> bound span a region which is shown alongside with the outcome of the (second stage) RSA.</p>
</section>
<section id="sec-NCsh-RSA" class="level2" data-number="3.2">
<h2 data-number="3.2" class="anchored" data-anchor-id="sec-NCsh-RSA"><span class="header-section-number">3.2</span> Split-half approach (single-participant or group level)</h2>
<p>I have not found any practical example where split half noise ceiling <span class="math inline">\(\nu_{sh}\)</span> is used in the context of <em>RSA</em>, but rather for calculation of noise ceilings in other contexts. However, <span class="citation" data-cites="lage-castellanos2019">Lage-Castellanos et al. (<a href="#ref-lage-castellanos2019" role="doc-biblioref">2019</a>)</span> proposes this method also for RSA matrices, without going into detail. For typical (second stage) <em>RSA</em> (on the single participant level), the idea would roughly be the follows:</p>
<ol type="1">
<li>Split the trials per condition in half, and estimate from each respective half the corresponding <em>RSA</em>, <span class="math inline">\(D_{i,1}\)</span> and <span class="math inline">\(D_{i,2}\)</span></li>
<li>Correlate the (lower diagonal) of <span class="math inline">\(D_{i,1}\)</span> and <span class="math inline">\(D_{i,2}\)</span> (<a href="#eq-castellanos1">Equation&nbsp;3</a>).</li>
<li>Adjust this correlation coefficient for the reduced number of samples that enter the correlation in the split-half approach compared to a correlation that would use as many data as the full data set had for each partner that enters the correlation (<a href="#eq-castellanos2">Equation&nbsp;4</a>).</li>
</ol>
<p><span id="eq-castellanos1"><span class="math display">\[
\nu_{sh,unadj} = \dfrac{cov(\hat{\beta_1},\hat{\beta_2})}{\sqrt{\hat{\sigma_{\hat{\beta_1}}} \hat{\sigma_{\hat{\beta_2}}}}}
\tag{3}\]</span></span></p>
<p>where <span class="math inline">\(\beta\)</span> are estimates from fMRI GLMs of the respective two splits.</p>
<p><span id="eq-castellanos2"><span class="math display">\[
\nu_{sh} = \sqrt{\dfrac{2\nu_{sh,unadj}}{\nu_{sh,unadj}+1}}
\tag{4}\]</span></span></p>
<p>However, see <a href="#sec-adj">Section&nbsp;5</a> and <a href="#sec-adj-sb">Section&nbsp;5.1</a>, as it is unclear, which version is correct for <a href="#eq-castellanos2">Equation&nbsp;4</a>. Also note, that for group level, the adjustment factor might maybe not work, as the Spearman-Brown adjustment factor (<a href="#sec-adj-sb">Section&nbsp;5.1</a>) might be rather made for an individual level correlation value adjustment (TODO: check if this is correct). But maybe the method proposed in <a href="#sec-adj-emp">Section&nbsp;5.2</a> might work.</p>
</section>
</section>
<section id="sec-NC-PSM" class="level1" data-number="4">
<h1 data-number="4"><span class="header-section-number">4</span> Proposed method: noise ceiling for participant-level RSMs (first stage RSA)</h1>
<p>For the sake of clarity, we define any symmetric <span class="math inline">\(D_i\)</span> for participant <span class="math inline">\(i\)</span> as a matrix with its on- (<span class="math inline">\(d_{q,q}\)</span>) and off-diagonal (<span class="math inline">\(d_{q,p}^{(q \ne p)}\)</span>) elements as in <a href="#eq-def">Equation&nbsp;5</a>.</p>
<p><span id="eq-def"><span class="math display">\[
D_i = \begin{pmatrix}
d_{1,1} &amp; d_{1,2} &amp; d_{1,3} &amp; d_{1,4} \\
d_{2,1} &amp; d_{2,2} &amp; d_{2,3} &amp; d_{2,4} \\
d_{3,1} &amp; d_{3,2} &amp; d_{3,3} &amp; d_{3,4} \\
d_{4,1} &amp; d_{4,2} &amp; d_{4,3} &amp; d_{4,4}
\end{pmatrix} % bmatrix with brackets
\tag{5}\]</span></span></p>
<p>We want to estimate a noise ceiling , that is, the maximal possible correlation value that can be achieved, given the noise conditions. In <em>RSMs</em> (first stage <em>RSA</em>) this is the maximal possible correlation value we can expect within the <em>RSM.</em> The on-diagonal elements offer themselves as natural noise ceiling, as their value of <span class="math inline">\(1\)</span> is are the upper bound of what can be achieved, namely the correlation of the pattern vectors <span class="math inline">\(v_k\)</span> with themselves. However, this value is overestimated, then even with pure noise in the data, the on-diagonals would be <span class="math inline">\(1\)</span>. However, we could use a split-half approach.</p>
<p>For instance, we have a <span class="math inline">\(D_i\)</span> estimated on the full data and we want to estimate <span class="math inline">\(\nu\)</span> for one particular element <span class="math inline">\(d_{q,p}^{(q \ne p)}\)</span> of <span class="math inline">\(D_i\)</span>, i.e., for one off-diagonal correlation coefficient. We split the data set in two halves, and estimate <span class="math inline">\(D_{i,sh}\)</span> by correlating <span class="math inline">\(v_{k,1}\)</span> (1st half) and <span class="math inline">\(v_{k,2}\)</span> (2nd half), which are e.g.&nbsp;the ERPs from the respective half of epochs, effectively making <span class="math inline">\(D_{i,sh}\)</span> asymmetric (<a href="#eq-defsh">Equation&nbsp;6</a>). (Similar <a href="http://www.newbi4fmri.com/tutorial-9-mvpa-rsa">as done here</a> for a different purpose).</p>
<p><span id="eq-defsh"><span class="math display">\[
D_{i,sh} = \begin{pmatrix}
d_{1,1}^{sh} &amp; d_{1,2}^{sh} &amp; d_{1,3}^{sh} &amp; d_{1,4}^{sh} \\
d_{2,1}^{sh} &amp; d_{2,2}^{sh} &amp; d_{2,3}^{sh} &amp; d_{2,4}^{sh} \\
d_{3,1}^{sh} &amp; d_{3,2}^{sh} &amp; d_{3,3}^{sh} &amp; d_{3,4}^{sh} \\
d_{4,1}^{sh} &amp; d_{4,2}^{sh} &amp; d_{4,3}^{sh} &amp; d_{4,4}^{sh}
\end{pmatrix} % bmatrix with brackets
\tag{6}\]</span></span></p>
<p>We need to make one assumption: the noise structure is the same in all <span class="math inline">\(k\)</span> conditions.</p>
<p>Then we can treat the on-diagonals <span class="math inline">\(d_{q,q}^{sh}\)</span> as the noise ceiling of the off-diagonals <span class="math inline">\(d_{q,p}^{(q \ne p), sh}\)</span>. The on-diagonals are the correlations within the same category, whereas the off-diagonals are correlations between categories. Our assumption is, that the correlation of one category with itself is the maximal possible correlation that can be achieved. Whereas <span class="math inline">\(d_{q,q}\)</span> were estimated to <span class="math inline">\(1\)</span>, as there was not another test set of <span class="math inline">\(v_k\)</span> to be correlated with, <span class="math inline">\(d_{q,q}^{sh}\)</span> was estimated by two sets of <span class="math inline">\(v_k\)</span>.</p>
<p>The interpretation of the noise ceiling is slighly different than the noise ceiling estimated for the correlation between <span class="math inline">\(D\)</span> and <span class="math inline">\(M\)</span>, which is typically for model comparison and states, how well a model can theoretically achieve. Here, it’s how well a correlation coefficient can score between categories, and this becomes higher and higher, as more similar the categories are, peaking in the highest possible correlation, when the categories the same (but the trials used for calculation are different).</p>
<p>Assuming equal noise structure through all categories, one could estimate <span class="math inline">\(\nu_{sh, unadj}\)</span> as average over all (r-to-z transformed and backtransformed) on-diagonals <span class="math inline">\(d_{q,q}^{sh}\)</span>, i.e.:</p>
<p><span id="eq-sh-psm"><span class="math display">\[
\nu_{sh, unadj} = tanh \left( \frac{1}{k} \sum_q^k arctanh(d_{q,q}^{sh}) \right)
\tag{7}\]</span></span></p>
<p>The split-half approach could be repeated with e.g., 1000 different splits to get a more stable estimate of <span class="math inline">\(\nu_{sh, unadj}\)</span>, i.e., stratified Monte Carlo splitting.</p>
<p>Now we need to adjust this value for the reduced amount of data in the split half approach (<a href="#sec-adj">Section&nbsp;5</a>).</p>
</section>
<section id="sec-adj" class="level1" data-number="5">
<h1 data-number="5"><span class="header-section-number">5</span> Adjustment coefficient</h1>
<p>When calculating the split-half noise ceiling (<span class="math inline">\(\nu_{sh}\)</span>) via a correlation coefficient, the correlation estimate is biased downwards because the correlation does not have the same amount of data, then the original correlation had, for which the <span class="math inline">\(\nu\)</span> is to be estimated. If one has an abundance of data, and does not care about dropping half of it, one could just use the full data set for noise ceiling estimation, and then drop half of it. Then one has an accurate noise ceiling estimate for correlations for the <span class="math inline">\(D_i\)</span> or <span class="math inline">\(D\)</span> of the remaining trials with a potential <span class="math inline">\(M\)</span> (i.e., the second stage and often main part of interest of the <em>RSA</em>). The same logic should count for <span class="math inline">\(\nu_{sh}\)</span> estimation for <em>PSM/RSM</em>s.</p>
<section id="sec-adj-sb" class="level2" data-number="5.1">
<h2 data-number="5.1" class="anchored" data-anchor-id="sec-adj-sb"><span class="header-section-number">5.1</span> Spearman-Brown prophecy formula</h2>
<p>The recent paper of <span class="citation" data-cites="lage-castellanos2019">Lage-Castellanos et al. (<a href="#ref-lage-castellanos2019" role="doc-biblioref">2019</a>)</span> mentions an adjustment for this underestimation (<a href="#eq-castellanos1">Equation&nbsp;3</a> &amp; <a href="#eq-castellanos2">Equation&nbsp;4</a>). They reference <span class="citation" data-cites="huth2012">Huth et al. (<a href="#ref-huth2012" role="doc-biblioref">2012</a>)</span> and <span class="citation" data-cites="luking2017">Luking et al. (<a href="#ref-luking2017" role="doc-biblioref">2017</a>)</span> for the <span class="math inline">\(\nu_{sh}\)</span> calculation. The origin of the adjustment factor (<a href="#eq-castellanos2">Equation&nbsp;4</a>) is not clear. <span class="citation" data-cites="luking2017">Luking et al. (<a href="#ref-luking2017" role="doc-biblioref">2017</a>)</span> name the <em>Spearman-Brown prophecy formula</em> to adjust for their split-half Pearson correlation coefficient used, writing the formula</p>
<p><span id="eq-luking1"><span class="math display">\[
\nu_{sh} = \dfrac{2 \nu_{sh,unadj}}{1+ \nu_{sh,unadj}}
\tag{8}\]</span></span></p>
<p>The origin of the square root in <a href="#eq-castellanos2">Equation&nbsp;4</a> compared to <a href="#eq-luking1">Equation&nbsp;8</a> is not clear. However, it inflates the noise ceiling estimation. <span class="citation" data-cites="warrens2016">Warrens (<a href="#ref-warrens2016" role="doc-biblioref">2016</a>)</span>, to which the r package <em>splithalfr</em> refers to, and <span class="citation" data-cites="pronk2022">Pronk et al. (<a href="#ref-pronk2022" role="doc-biblioref">2022</a>)</span>, also use <a href="#eq-luking1">Equation&nbsp;8</a> and states, that it the method holds only if <span class="math inline">\(\sigma_1^{sh}\)</span> and <span class="math inline">\(\sigma_2^{sh}\)</span> do not differ substantially, and if the lengths of the two halves do not differ significantly. <span class="citation" data-cites="warrens2016">Warrens (<a href="#ref-warrens2016" role="doc-biblioref">2016</a>)</span> also introduces alternative adjustment factors.</p>
<p>Maybe: is <a href="#eq-castellanos2">Equation&nbsp;4</a> thinking it’s an <span class="math inline">\(R^2\)</span> estimate instead of <span class="math inline">\(\rho\)</span>, and therefore for some reasons use square root?</p>
<p><span class="citation" data-cites="huth2012">Huth et al. (<a href="#ref-huth2012" role="doc-biblioref">2012</a>)</span> only briefly mentions noise ceiling estimation in the appendix, with reference to <span class="citation" data-cites="hsu2004">Hsu, Borst, and Theunissen (<a href="#ref-hsu2004" role="doc-biblioref">2004</a>)</span>, which seems mathematical rather complex, and based on spike train data (also could not find an exact formula on which this is based on).</p>
<p><a href="https://en.wikipedia.org/wiki/Spearman–Brown_prediction_formula">Wikipedia</a> also describes the Spearman-Brown Formula as</p>
<p><span id="eq-SB"><span class="math display">\[
\nu_{adj}=\frac{n \nu_{sh,unadj}}{1+(n-1) \nu_{sh,unadj}}
\tag{9}\]</span></span></p>
<p>where <span class="math inline">\(n\)</span> is the factor by which the length of the data is changed, i.e., if reduced from 10 to 5, then it’s 2. If <span class="math inline">\(n=2\)</span> such as in split half noise ceiling estimation, then this reduced to <a href="#eq-luking1">Equation&nbsp;8</a>.</p>
</section>
<section id="sec-adj-emp" class="level2" data-number="5.2">
<h2 data-number="5.2" class="anchored" data-anchor-id="sec-adj-emp"><span class="header-section-number">5.2</span> Empirical adjustment factor / projection factor</h2>
<p>Here, an empirical adjustment factor is proposed. The idea is simple, and I don’t find reasons why it should be less accurate (TODO: simulate?) than the analytic suggestion of <span class="citation" data-cites="lage-castellanos2019">Lage-Castellanos et al. (<a href="#ref-lage-castellanos2019" role="doc-biblioref">2019</a>)</span>, of which the origin is not fully traceable right now.</p>
<p>We already estimated unadjusted split half noise ceilings in <a href="#sec-NC-PSM">Section&nbsp;4</a> via <a href="#eq-sh-psm">Equation&nbsp;7</a> as an average of on-diagonal correlation coefficients.</p>
<p>Now we could use the off-diagonal elements <span class="math inline">\(d_{q,p}^{(q \ne p)}\)</span> to estimate the adjustment factor. We know the original correlation values of the full-data RSM <span class="math inline">\(D_i\)</span>. Further, we already estimated the split half data RSM <span class="math inline">\(D_{i,sh}\)</span> and its off-diagonal values <span class="math inline">\(d_{q,p}^{(q \ne p), sh}\)</span>. We could now average (with r-to-z-transform and back) the off-diagonals of <span class="math inline">\(D_i\)</span> and <span class="math inline">\(D_{i,sh}\)</span>, respectively, and obtain <span class="math inline">\(r_f\)</span> and <span class="math inline">\(r_p\)</span> (the full and partial correlation coefficients) (Note that all are z values).</p>
<p>The adjustment factor <span class="math inline">\(\beta\)</span> is then</p>
<p><span class="math display">\[
\beta =  \frac{r_f}{r_p}
\]</span></p>
<p>We can simply multiply <span class="math inline">\(\beta\)</span> with the <span class="math inline">\(\nu_{sh,unadj}\)</span> to get a <span class="math inline">\(\nu_{sh}\)</span> value, which can be used as estimate for noise ceiling.</p>
<p><span class="math display">\[
\nu_{sh,adj} =  \beta \times \nu_{sh, unadj}
\]</span></p>
<div id="alg-quicksort" class="pseudocode-container" data-line-number-punc=":" data-comment-delimiter="//" data-no-end="false" data-pseudocode-index="1" data-line-number="true" data-indent-size="1.2em" data-alg-title="Algorithm">
<div class="pseudocode">
\begin{algorithm} \caption{RSM split half noise ceiling} \begin{algorithmic} \Procedure{estimate split half correlation}{$A, p, r$} \If{$p &lt; r$} \State $q = $ \Call{Partition}{$A, p, r$} \State \Call{Quicksort}{$A, p, q - 1$} \State \Call{Quicksort}{$A, q + 1, r$} \EndIf \EndProcedure \Procedure{empirical projection}{$A, p, r$} \State $x = A[r]$ \State $i = p - 1$ \For{$j = p$ \To $r - 1$} \If{$A[j] &lt; x$} \State $i = i + 1$ \State exchange $A[i]$ with $A[j]$ \EndIf \State exchange $A[i]$ with $A[r]$ \EndFor \EndProcedure \end{algorithmic} \end{algorithm}
</div>
</div>
</section>
</section>
<section id="sec-tr" class="level1" data-number="6">
<h1 data-number="6"><span class="header-section-number">6</span> Time-resolved or concatenated analysis?</h1>
<p>WIP</p>
<p>The EEG literature is full of time-resolved second stage RSA (e.g., XXXREF, XXXREF, XXXREF). However, for first-stage RSA, one might be interested in the pattern similarity over a particular time window (e.g.&nbsp;post-stimulus onset) rather than each timepoint individually. Possible options, however not yet found in the literature are:</p>
<ol type="1">
<li>Concatenating electrode voltages over time and correlating concatenated vectors rather than only channel activations of one timepoint</li>
<li>Do the usual (first stage) RSA for each time point, and average (z-transformed) RSMs across time.</li>
</ol>
</section>
<section id="sandbox" class="level1" data-number="7">
<h1 data-number="7"><span class="header-section-number">7</span> Sandbox</h1>
<p>WIP</p>
<p>for RSA (2nd level) TODO: does it work even?</p>
<p>For instance, we have a <em>data RSM</em> and want to estimate the NC for the comparison to a <em>model RSM</em> (i.e., 2nd level of a typical <em>RSA</em>). One would split the data set into half, generate 2 <em>RSM</em>s, and correlate the off-diagonals of these <em>RSMs</em>. The resulting adjustment coefficient is the noise ceiling, but needs to be adjusted. Therefore, we calculate</p>
</section>
<section id="references" class="level1" data-number="8">
<h1 data-number="8"><span class="header-section-number">8</span> References</h1>
<div id="refs" class="references csl-bib-body hanging-indent" role="doc-bibliography">
<div id="ref-carlin2017" class="csl-entry" role="doc-biblioentry">
Carlin, Johan D., and Nikolaus Kriegeskorte. 2017. <span>“Adjudicating Between Face-Coding Models with Individual-Face fMRI Responses.”</span> <em>PLOS Computational Biology</em> 13 (7): e1005604. <a href="https://doi.org/10.1371/journal.pcbi.1005604">https://doi.org/10.1371/journal.pcbi.1005604</a>.
</div>
<div id="ref-hsu2004" class="csl-entry" role="doc-biblioentry">
Hsu, Anne, Alexander Borst, and Frédéric E. Theunissen. 2004. <span>“Quantifying variability in neural responses and its application for the validation of model predictions.”</span> <em>Network (Bristol, England)</em> 15 (2): 91–109.
</div>
<div id="ref-huth2012" class="csl-entry" role="doc-biblioentry">
Huth, Alexander&nbsp;G., Shinji Nishimoto, An&nbsp;T. Vu, and Jack&nbsp;L. Gallant. 2012. <span>“A Continuous Semantic Space Describes the Representation of Thousands of Object and Action Categories Across the Human Brain.”</span> <em>Neuron</em> 76 (6): 1210–24. <a href="https://doi.org/10.1016/j.neuron.2012.10.014">https://doi.org/10.1016/j.neuron.2012.10.014</a>.
</div>
<div id="ref-kaniuth2022" class="csl-entry" role="doc-biblioentry">
Kaniuth, Philipp, and Martin N. Hebart. 2022. <span>“Feature-Reweighted Representational Similarity Analysis: A Method for Improving the Fit Between Computational Models, Brains, and Behavior.”</span> <em>NeuroImage</em> 257 (August): 119294. <a href="https://doi.org/10.1016/j.neuroimage.2022.119294">https://doi.org/10.1016/j.neuroimage.2022.119294</a>.
</div>
<div id="ref-kriegeskorte2008" class="csl-entry" role="doc-biblioentry">
Kriegeskorte, Nikolaus, Marieke Mur, and Peter Bandettini. 2008. <span>“Representational Similarity Analysis <span></span> Connecting the Branches of Systems Neuroscience.”</span> <em>Frontiers in Systems Neuroscience</em>. <a href="https://doi.org/10.3389/neuro.06.004.2008">https://doi.org/10.3389/neuro.06.004.2008</a>.
</div>
<div id="ref-lage-castellanos2019" class="csl-entry" role="doc-biblioentry">
Lage-Castellanos, Agustin, Giancarlo Valente, Elia Formisano, and Federico De Martino. 2019. <span>“Methods for Computing the Maximum Performance of Computational Models of fMRI Responses.”</span> Edited by Jörn Diedrichsen. <em>PLOS Computational Biology</em> 15 (3): e1006397. <a href="https://doi.org/10.1371/journal.pcbi.1006397">https://doi.org/10.1371/journal.pcbi.1006397</a>.
</div>
<div id="ref-luking2017" class="csl-entry" role="doc-biblioentry">
Luking, Katherine R., Brady D. Nelson, Zachary P. Infantolino, Colin L. Sauder, and Greg Hajcak. 2017. <span>“Internal Consistency of Functional Magnetic Resonance Imaging and Electroencephalography Measures of Reward in Late Childhood and Early Adolescence.”</span> <em>Biological Psychiatry: Cognitive Neuroscience and Neuroimaging</em> 2 (3): 289–97. <a href="https://doi.org/10.1016/j.bpsc.2016.12.004">https://doi.org/10.1016/j.bpsc.2016.12.004</a>.
</div>
<div id="ref-nili2014" class="csl-entry" role="doc-biblioentry">
Nili, Hamed, Cai Wingfield, Alexander Walther, Li Su, William Marslen-Wilson, and Nikolaus Kriegeskorte. 2014. <span>“A Toolbox for Representational Similarity Analysis.”</span> <em>PLOS Computational Biology</em> 10 (4): e1003553. <a href="https://doi.org/10.1371/journal.pcbi.1003553">https://doi.org/10.1371/journal.pcbi.1003553</a>.
</div>
<div id="ref-pronk2022" class="csl-entry" role="doc-biblioentry">
Pronk, Thomas, Dylan Molenaar, Reinout W. Wiers, and Jaap Murre. 2022. <span>“Methods to Split Cognitive Task Data for Estimating Split-Half Reliability: A Comprehensive Review and Systematic Assessment.”</span> <em>Psychonomic Bulletin &amp; Review</em> 29 (1): 44–54. <a href="https://doi.org/10.3758/s13423-021-01948-3">https://doi.org/10.3758/s13423-021-01948-3</a>.
</div>
<div id="ref-warrens2016" class="csl-entry" role="doc-biblioentry">
Warrens, Matthijs J. 2016. <span>“A Comparison of Reliability Coefficients for Psychometric Tests That Consist of Two Parts.”</span> <em>Advances in Data Analysis and Classification</em> 10 (1): 71–84. <a href="https://doi.org/10.1007/s11634-015-0198-6">https://doi.org/10.1007/s11634-015-0198-6</a>.
</div>
<div id="ref-xie2022" class="csl-entry" role="doc-biblioentry">
Xie, Siying, Stefanie Hoehl, Merle Moeskops, Ezgi Kayhan, Christian Kliesch, Bert Turtleton, Moritz Köster, and Radoslaw M. Cichy. 2022. <span>“Visual Category Representations in the Infant Brain.”</span> <em>Current Biology</em> 32 (24): 5422–5432.e6. <a href="https://doi.org/10.1016/j.cub.2022.11.016">https://doi.org/10.1016/j.cub.2022.11.016</a>.
</div>
</div>
</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->
<script src="https://cdn.jsdelivr.net/npm/pseudocode@latest/build/pseudocode.min.js" type="text/javascript"></script>
<script type="text/javascript">
(function(d) {
  d.querySelectorAll(".pseudocode-container").forEach(function(el) {
    let pseudocodeOptions = {
      indentSize: el.dataset.indentSize || "1.2em",
      commentDelimiter: el.dataset.commentDelimiter || "//",
      lineNumber: el.dataset.lineNumber === "true" ? true : false,
      lineNumberPunc: el.dataset.lineNumberPunc || ":",
      noEnd: el.dataset.noEnd === "true" ? true : false,
      titlePrefix: el.dataset.algTitle || "Algorithm"
    };
    pseudocode.renderElement(el.querySelector(".pseudocode"), pseudocodeOptions);
  });
})(document);
(function(d) {
  d.querySelectorAll(".pseudocode-container").forEach(function(el) {
    titleSpan = el.querySelector(".ps-root > .ps-algorithm > .ps-line > .ps-keyword")
    titlePrefix = el.dataset.algTitle;
    titleIndex = el.dataset.chapterLevel ? el.dataset.chapterLevel + "." + el.dataset.pseudocodeIndex : el.dataset.pseudocodeIndex;
    titleSpan.innerHTML = titlePrefix + " " + titleIndex + " ";
  });
})(document);
</script>



</body></html>