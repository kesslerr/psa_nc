% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames,x11names}{xcolor}
%
\documentclass[
  letterpaper,
  DIV=11,
  numbers=noendperiod]{scrartcl}

\usepackage{amsmath,amssymb}
\usepackage{lmodern}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\setlength{\emergencystretch}{3em} % prevent overfull lines
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering
% Make \paragraph and \subparagraph free-standing
\ifx\paragraph\undefined\else
  \let\oldparagraph\paragraph
  \renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
  \let\oldsubparagraph\subparagraph
  \renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi


\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\newlength{\cslhangindent}
\setlength{\cslhangindent}{1.5em}
\newlength{\csllabelwidth}
\setlength{\csllabelwidth}{3em}
\newlength{\cslentryspacingunit} % times entry-spacing
\setlength{\cslentryspacingunit}{\parskip}
\newenvironment{CSLReferences}[2] % #1 hanging-ident, #2 entry spacing
 {% don't indent paragraphs
  \setlength{\parindent}{0pt}
  % turn on hanging indent if param 1 is 1
  \ifodd #1
  \let\oldpar\par
  \def\par{\hangindent=\cslhangindent\oldpar}
  \fi
  % set entry spacing
  \setlength{\parskip}{#2\cslentryspacingunit}
 }%
 {}
\usepackage{calc}
\newcommand{\CSLBlock}[1]{#1\hfill\break}
\newcommand{\CSLLeftMargin}[1]{\parbox[t]{\csllabelwidth}{#1}}
\newcommand{\CSLRightInline}[1]{\parbox[t]{\linewidth - \csllabelwidth}{#1}\break}
\newcommand{\CSLIndent}[1]{\hspace{\cslhangindent}#1}

\KOMAoption{captions}{tableheading}
\usepackage{algorithm2e}
\makeatletter
\makeatother
\makeatletter
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\AtBeginDocument{%
\ifdefined\contentsname
  \renewcommand*\contentsname{Table of contents}
\else
  \newcommand\contentsname{Table of contents}
\fi
\ifdefined\listfigurename
  \renewcommand*\listfigurename{List of Figures}
\else
  \newcommand\listfigurename{List of Figures}
\fi
\ifdefined\listtablename
  \renewcommand*\listtablename{List of Tables}
\else
  \newcommand\listtablename{List of Tables}
\fi
\ifdefined\figurename
  \renewcommand*\figurename{Figure}
\else
  \newcommand\figurename{Figure}
\fi
\ifdefined\tablename
  \renewcommand*\tablename{Table}
\else
  \newcommand\tablename{Table}
\fi
}
\@ifpackageloaded{float}{}{\usepackage{float}}
\floatstyle{ruled}
\@ifundefined{c@chapter}{\newfloat{codelisting}{h}{lop}}{\newfloat{codelisting}{h}{lop}[chapter]}
\floatname{codelisting}{Listing}
\newcommand*\listoflistings{\listof{codelisting}{List of Listings}}
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\@ifpackageloaded{subcaption}{}{\usepackage{subcaption}}
\makeatother
\makeatletter
\@ifpackageloaded{tcolorbox}{}{\usepackage[many]{tcolorbox}}
\makeatother
\makeatletter
\@ifundefined{shadecolor}{\definecolor{shadecolor}{rgb}{.97, .97, .97}}
\makeatother
\makeatletter
\makeatother
\makeatletter
\@ifpackageloaded{algorithm}{}{\usepackage{algorithm}}
\makeatother
\makeatletter
\@ifpackageloaded{algpseudocode}{}{\usepackage{algpseudocode}}
\makeatother
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same} % disable monospaced font for URLs
\hypersetup{
  pdftitle={Noise Ceiling Estimation for Representational Similarity Matrices},
  colorlinks=true,
  linkcolor={blue},
  filecolor={Maroon},
  citecolor={Blue},
  urlcolor={Blue},
  pdfcreator={LaTeX via pandoc}}

\title{Noise Ceiling Estimation for Representational Similarity
Matrices}
\author{}
\date{}

\begin{document}
\maketitle
\ifdefined\Shaded\renewenvironment{Shaded}{\begin{tcolorbox}[boxrule=0pt, interior hidden, breakable, borderline west={3pt}{0pt}{shadecolor}, sharp corners, enhanced, frame hidden]}{\end{tcolorbox}}\fi

\floatname{algorithm}{Algorithm}

more about Quarto see \url{https://quarto.org}.

\hypertarget{sec-RSA}{%
\section{Representational Similarity Analysis (RSA) in a
nutshell}\label{sec-RSA}}

The idea is to compare the representational geometry of some neural data
with that of a model (Kriegeskorte, Mur, and Bandettini
(\protect\hyperlink{ref-kriegeskorte2008}{2008})). For example, we
stimulate participants with each several repetitions of different visual
stimulus categories. In fMRI, we then run a GLM with separate regressors
per \(k\) category, extract the voxel estimates and put them into a
vector \(v_k\) of a particular ROI we are interested in. For MEEG,
\(v_k\) is typically composed of the electrical potentials from the
different channels (e.g., electrodes) of an grand average event-related
potential (ERP) -- an average over several dozens of repetitions or
epochs, and the following is then estimated for each time point of the
ERP separately (but see Section~\ref{sec-tr}). We then correlate all
\(v_k\) with each other to get a \(k \times k\) (symmetric)
representational similarity matrix (\emph{RSM}) \(D\) (or pattern
similarity matrix \emph{PSM}) representing the neural data (\emph{data
RSM}). For simplicity, and for the sake of this work, this part of the
analysis will be named \emph{first stage} of an \emph{RSA}.

However, the main interest lies usually on the results of a second stage
of an \emph{RSA}. The lower triangle of \(D\) is then (rank) correlated
with a \(k \times k\) \emph{model RSM} \(M\). Different \(M\) can be
compared to each other, e.g.~via the magnitude of their correlation with
\(D\). For group level inference, \(D\) can be averaged (but see
Section~\ref{sec-Fisher}) to \(\bar{D}\), and the result can be (rank)
correlated with \(M\).

\hypertarget{sec-Fisher}{%
\section{Excursion: Fisher-r-to-z transformation of correlation
coefficients}\label{sec-Fisher}}

Fisher r-to-z transformation (i.e., \(z=arctanh(r)\) or
Equation~\ref{eq-r2z}) for correlation coefficients (including those for
noise ceilings) is often not reported in the RSA literature (exceptions,
e.g., Carlin and Kriegeskorte (\protect\hyperlink{ref-carlin2017}{2017})
), and some packages even haven't implemented it for some reasons (e.g.,
see discussion
\href{https://github.com/rsagroup/rsatoolbox/issues/370}{here}).

\begin{equation}\protect\hypertarget{eq-r2z}{}{
z = \frac{1}{2} ln \left[  \dfrac{1+r}{1-r} \right]
}\label{eq-r2z}\end{equation}

For steps in which any \(r\) needs to be averaged (e.g., across samples,
or across subjects), mean \(r\) is however biased, especially for
\(r > 0.5\). The numeric difference for low \(r\) can be treated as
neglectable. However, due to the low costs of transformation, I will
always implicitly assume that \(r\) values are transformed to \(z\) for
each step that includes e.g., averaging or statistics. After that being
done, for the sake of easier interpretability, it is then transformed
back using \(r = tanh(z)\) or Equation~\ref{eq-z2r}

\begin{equation}\protect\hypertarget{eq-z2r}{}{
r = \dfrac{e^{2z}-1}{e^{2z}+1}
}\label{eq-z2r}\end{equation}

\hypertarget{sec-NC-RSA}{%
\section{Noise ceiling (NC) for (second stage) RSA}\label{sec-NC-RSA}}

To get an estimate of how well the best possible model could perform,
given the noise conditions in the data, noise ceilings (\emph{NC} or
\(\nu\)) can be estimated (e.g., Lage-Castellanos et al.
(\protect\hyperlink{ref-lage-castellanos2019}{2019})). I found versions
suitable for RSA. Both of them are applied to estimate NCs for second
stage RSA.

\hypertarget{sec-NCbound-RSA}{%
\subsection{Boundary procedure (group level
inference)}\label{sec-NCbound-RSA}}

The boundary procedure was for example used in Kaniuth and Hebart
(\protect\hyperlink{ref-kaniuth2022}{2022}) and Xie et al.
(\protect\hyperlink{ref-xie2022}{2022}) and implemented in Nili et al.
(\protect\hyperlink{ref-nili2014}{2014}). The lower \(\nu_{lower}\) and
upper bound \(\nu_{upper}\) of the noise ceiling are estimated
separately:

For the upper bound

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Estimate an average \(D\) (\(\bar{D}\)) across participants.
\item
  Correlate the (lower triangular) of each participants \(D_i\) to
  \(\bar{D}\), and retrieve \(\nu_{u,i}\)
\item
  Average across \(\nu_{u,i}\), to get \(\nu_{upper}\)
\end{enumerate}

This is the upper bound, because it is an overestimated noise ceiling,
as \(\bar{D}\) and \(D_i\) share some information about one participant.

For the lower bound,

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  For each participant, estimate \(\bar{D}^{(-i)}\) across participants,
  which is the average \(D\) but without participant \(i\).
\item
  Correlate the (lower triangular) of each \(D_i\) to
  \(\bar{D}^{(-i)}\), and retrieve \(\nu_{l,i}\)
\item
  Average across \(\nu_{l,i}\), to get \(\nu_{lower}\)
\end{enumerate}

This is the lower bound, because \(\bar{D}^{(-i)}\) does not have as
much data as \(\bar{D}\) (i.e., participant \(i\)). Typically, \(\nu_l\)
and \(\nu_u\) bound span a region which is shown alongside with the
outcome of the (second stage) RSA.

\hypertarget{sec-NCsh-RSA}{%
\subsection{Split-half approach (single-participant or group
level)}\label{sec-NCsh-RSA}}

I have not found any practical example where split half noise ceiling
\(\nu_{sh}\) is used in the context of \emph{RSA}, but rather for
calculation of noise ceilings in other contexts. However,
Lage-Castellanos et al.
(\protect\hyperlink{ref-lage-castellanos2019}{2019}) proposes this
method also for RSA matrices, without going into detail. For typical
(second stage) \emph{RSA} (on the single participant level), the idea
would roughly be the follows:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Split the trials per condition in half, and estimate from each
  respective half the corresponding \emph{RSA}, \(D_{i,1}\) and
  \(D_{i,2}\)
\item
  Correlate the (lower diagonal) of \(D_{i,1}\) and \(D_{i,2}\)
  (Equation~\ref{eq-castellanos1}).
\item
  Adjust this correlation coefficient for the reduced number of samples
  that enter the correlation in the split-half approach compared to a
  correlation that would use as many data as the full data set had for
  each partner that enters the correlation
  (Equation~\ref{eq-castellanos2}).
\end{enumerate}

\begin{equation}\protect\hypertarget{eq-castellanos1}{}{
\nu_{sh,unadj} = \dfrac{cov(\hat{\beta_1},\hat{\beta_2})}{\sqrt{\hat{\sigma_{\hat{\beta_1}}} \hat{\sigma_{\hat{\beta_2}}}}}
}\label{eq-castellanos1}\end{equation}

where \(\beta\) are estimates from fMRI GLMs of the respective two
splits.

\begin{equation}\protect\hypertarget{eq-castellanos2}{}{
\nu_{sh} = \sqrt{\dfrac{2\nu_{sh,unadj}}{\nu_{sh,unadj}+1}}
}\label{eq-castellanos2}\end{equation}

However, see Section~\ref{sec-adj} and Section~\ref{sec-adj-sb}, as it
is unclear, which version is correct for Equation~\ref{eq-castellanos2}.
Also note, that for group level, the adjustment factor might maybe not
work, as the Spearman-Brown adjustment factor (Section~\ref{sec-adj-sb})
might be rather made for an individual level correlation value
adjustment (TODO: check if this is correct). But maybe the method
proposed in Section~\ref{sec-adj-emp} might work.

\hypertarget{sec-NC-PSM}{%
\section{Proposed method: noise ceiling for participant-level RSMs
(first stage RSA)}\label{sec-NC-PSM}}

For the sake of clarity, we define any symmetric \(D_i\) for participant
\(i\) as a matrix with its on- (\(d_{q,q}\)) and off-diagonal
(\(d_{q,p}^{(q \ne p)}\)) elements as in Equation~\ref{eq-def}.

\begin{equation}\protect\hypertarget{eq-def}{}{ 
D_i = \begin{pmatrix}
d_{1,1} & d_{1,2} & d_{1,3} & d_{1,4} \\
d_{2,1} & d_{2,2} & d_{2,3} & d_{2,4} \\
d_{3,1} & d_{3,2} & d_{3,3} & d_{3,4} \\
d_{4,1} & d_{4,2} & d_{4,3} & d_{4,4} 
\end{pmatrix} % bmatrix with brackets
}\label{eq-def}\end{equation}

We want to estimate a noise ceiling , that is, the maximal possible
correlation value that can be achieved, given the noise conditions. In
\emph{RSMs} (first stage \emph{RSA}) this is the maximal possible
correlation value we can expect within the \emph{RSM.} The on-diagonal
elements offer themselves as natural noise ceiling, as their value of
\(1\) is are the upper bound of what can be achieved, namely the
correlation of the pattern vectors \(v_k\) with themselves. However,
this value is overestimated, then even with pure noise in the data, the
on-diagonals would be \(1\). However, we could use a split-half
approach.

For instance, we have a \(D_i\) estimated on the full data and we want
to estimate \(\nu\) for one particular element \(d_{q,p}^{(q \ne p)}\)
of \(D_i\), i.e., for one off-diagonal correlation coefficient. We split
the data set in two halves, and estimate \(D_{i,sh}\) by correlating
\(v_{k,1}\) (1st half) and \(v_{k,2}\) (2nd half), which are e.g.~the
ERPs from the respective half of epochs, effectively making \(D_{i,sh}\)
asymmetric (Equation~\ref{eq-defsh}). (Similar
\href{http://www.newbi4fmri.com/tutorial-9-mvpa-rsa}{as done here} for a
different purpose).

\begin{equation}\protect\hypertarget{eq-defsh}{}{ 
D_{i,sh} = \begin{pmatrix}
d_{1,1}^{sh} & d_{1,2}^{sh} & d_{1,3}^{sh} & d_{1,4}^{sh} \\
d_{2,1}^{sh} & d_{2,2}^{sh} & d_{2,3}^{sh} & d_{2,4}^{sh} \\
d_{3,1}^{sh} & d_{3,2}^{sh} & d_{3,3}^{sh} & d_{3,4}^{sh} \\
d_{4,1}^{sh} & d_{4,2}^{sh} & d_{4,3}^{sh} & d_{4,4}^{sh} 
\end{pmatrix} % bmatrix with brackets
}\label{eq-defsh}\end{equation}

We need to make one assumption: the noise structure is the same in all
\(k\) conditions.

Then we can treat the on-diagonals \(d_{q,q}^{sh}\) as the noise ceiling
of the off-diagonals \(d_{q,p}^{(q \ne p), sh}\). The on-diagonals are
the correlations within the same category, whereas the off-diagonals are
correlations between categories. Our assumption is, that the correlation
of one category with itself is the maximal possible correlation that can
be achieved. Whereas \(d_{q,q}\) were estimated to \(1\), as there was
not another test set of \(v_k\) to be correlated with, \(d_{q,q}^{sh}\)
was estimated by two sets of \(v_k\).

The interpretation of the noise ceiling is slighly different than the
noise ceiling estimated for the correlation between \(D\) and \(M\),
which is typically for model comparison and states, how well a model can
theoretically achieve. Here, it's how well a correlation coefficient can
score between categories, and this becomes higher and higher, as more
similar the categories are, peaking in the highest possible correlation,
when the categories the same (but the trials used for calculation are
different).

Assuming equal noise structure through all categories, one could
estimate \(\nu_{sh, unadj}\) as average over all (r-to-z transformed and
backtransformed) on-diagonals \(d_{q,q}^{sh}\), i.e.:

\begin{equation}\protect\hypertarget{eq-sh-psm}{}{
\nu_{sh, unadj} = tanh \left( \frac{1}{k} \sum_q^k arctanh(d_{q,q}^{sh}) \right)
}\label{eq-sh-psm}\end{equation}

The split-half approach could be repeated with e.g., 1000 different
splits to get a more stable estimate of \(\nu_{sh, unadj}\), i.e.,
stratified Monte Carlo splitting.

Now we need to adjust this value for the reduced amount of data in the
split half approach (Section~\ref{sec-adj}).

\hypertarget{sec-adj}{%
\section{Adjustment coefficient}\label{sec-adj}}

When calculating the split-half noise ceiling (\(\nu_{sh}\)) via a
correlation coefficient, the correlation estimate is biased downwards
because the correlation does not have the same amount of data, then the
original correlation had, for which the \(\nu\) is to be estimated. If
one has an abundance of data, and does not care about dropping half of
it, one could just use the full data set for noise ceiling estimation,
and then drop half of it. Then one has an accurate noise ceiling
estimate for correlations for the \(D_i\) or \(D\) of the remaining
trials with a potential \(M\) (i.e., the second stage and often main
part of interest of the \emph{RSA}). The same logic should count for
\(\nu_{sh}\) estimation for \emph{PSM/RSM}s.

\hypertarget{sec-adj-sb}{%
\subsection{Spearman-Brown prophecy formula}\label{sec-adj-sb}}

The recent paper of Lage-Castellanos et al.
(\protect\hyperlink{ref-lage-castellanos2019}{2019}) mentions an
adjustment for this underestimation (Equation~\ref{eq-castellanos1} \&
Equation~\ref{eq-castellanos2}). They reference Huth et al.
(\protect\hyperlink{ref-huth2012}{2012}) and Luking et al.
(\protect\hyperlink{ref-luking2017}{2017}) for the \(\nu_{sh}\)
calculation. The origin of the adjustment factor
(Equation~\ref{eq-castellanos2}) is not clear. Luking et al.
(\protect\hyperlink{ref-luking2017}{2017}) name the \emph{Spearman-Brown
prophecy formula} to adjust for their split-half Pearson correlation
coefficient used, writing the formula

\begin{equation}\protect\hypertarget{eq-luking1}{}{
\nu_{sh} = \dfrac{2 \nu_{sh,unadj}}{1+ \nu_{sh,unadj}}
}\label{eq-luking1}\end{equation}

The origin of the square root in Equation~\ref{eq-castellanos2} compared
to Equation~\ref{eq-luking1} is not clear. However, it inflates the
noise ceiling estimation. Warrens
(\protect\hyperlink{ref-warrens2016}{2016}), to which the r package
\emph{splithalfr} refers to, and Pronk et al.
(\protect\hyperlink{ref-pronk2022}{2022}), also use
Equation~\ref{eq-luking1} and states, that it the method holds only if
\(\sigma_1^{sh}\) and \(\sigma_2^{sh}\) do not differ substantially, and
if the lengths of the two halves do not differ significantly. Warrens
(\protect\hyperlink{ref-warrens2016}{2016}) also introduces alternative
adjustment factors.

Maybe: is Equation~\ref{eq-castellanos2} thinking it's an \(R^2\)
estimate instead of \(\rho\), and therefore for some reasons use square
root?

Huth et al. (\protect\hyperlink{ref-huth2012}{2012}) only briefly
mentions noise ceiling estimation in the appendix, with reference to
Hsu, Borst, and Theunissen (\protect\hyperlink{ref-hsu2004}{2004}),
which seems mathematical rather complex, and based on spike train data
(also could not find an exact formula on which this is based on).

\href{https://en.wikipedia.org/wiki/Spearman–Brown_prediction_formula}{Wikipedia}
also describes the Spearman-Brown Formula as

\begin{equation}\protect\hypertarget{eq-SB}{}{
\nu_{adj}=\frac{n \nu_{sh,unadj}}{1+(n-1) \nu_{sh,unadj}}
}\label{eq-SB}\end{equation}

where \(n\) is the factor by which the length of the data is changed,
i.e., if reduced from 10 to 5, then it's 2. If \(n=2\) such as in split
half noise ceiling estimation, then this reduced to
Equation~\ref{eq-luking1}.

\hypertarget{sec-adj-emp}{%
\subsection{Empirical adjustment factor / projection
factor}\label{sec-adj-emp}}

Here, an empirical adjustment factor is proposed. The idea is simple,
and I don't find reasons why it should be less accurate (TODO:
simulate?) than the analytic suggestion of Lage-Castellanos et al.
(\protect\hyperlink{ref-lage-castellanos2019}{2019}), of which the
origin is not fully traceable right now.

We already estimated unadjusted split half noise ceilings in
Section~\ref{sec-NC-PSM} via Equation~\ref{eq-sh-psm} as an average of
on-diagonal correlation coefficients.

Now we could use the off-diagonal elements \(d_{q,p}^{(q \ne p)}\) to
estimate the adjustment factor. We know the original correlation values
of the full-data RSM \(D_i\). Further, we already estimated the split
half data RSM \(D_{i,sh}\) and its off-diagonal values
\(d_{q,p}^{(q \ne p), sh}\). We could now average (with r-to-z-transform
and back) the off-diagonals of \(D_i\) and \(D_{i,sh}\), respectively,
and obtain \(r_f\) and \(r_p\) (the full and partial correlation
coefficients) (Note that all are z values).

The adjustment factor \(\beta\) is then

\[
\beta =  \frac{r_f}{r_p}
\]

We can simply multiply \(\beta\) with the \(\nu_{sh,unadj}\) to get a
\(\nu_{sh}\) value, which can be used as estimate for noise ceiling.

\[
\nu_{sh,adj} =  \beta \times \nu_{sh, unadj} 
\]

\begin{algorithm}[htb!]
\caption{RSM split half noise ceiling}
\label{alg-quicksort}
\begin{algorithmic}[1]
\Procedure{estimate split half correlation}{$A, p, r$}
  \If{$p < r$}
    \State $q = $ \Call{Partition}{$A, p, r$}
    \State \Call{Quicksort}{$A, p, q - 1$}
    \State \Call{Quicksort}{$A, q + 1, r$}
  \EndIf
\EndProcedure
\Procedure{empirical projection}{$A, p, r$}
  \State $x = A[r]$
  \State $i = p - 1$
  \For{$j = p$ \To $r - 1$}
    \If{$A[j] < x$}
      \State $i = i + 1$
      \State exchange
      $A[i]$ with     $A[j]$
    \EndIf
    \State exchange $A[i]$ with $A[r]$
  \EndFor
\EndProcedure
\end{algorithmic}
\end{algorithm}

\hypertarget{sec-tr}{%
\section{Time-resolved or concatenated analysis?}\label{sec-tr}}

WIP

The EEG literature is full of time-resolved second stage RSA (e.g.,
XXXREF, XXXREF, XXXREF). However, for first-stage RSA, one might be
interested in the pattern similarity over a particular time window
(e.g.~post-stimulus onset) rather than each timepoint individually.
Possible options, however not yet found in the literature are:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Concatenating electrode voltages over time and correlating
  concatenated vectors rather than only channel activations of one
  timepoint
\item
  Do the usual (first stage) RSA for each time point, and average
  (z-transformed) RSMs across time.
\end{enumerate}

\hypertarget{sandbox}{%
\section{Sandbox}\label{sandbox}}

WIP

for RSA (2nd level) TODO: does it work even?

For instance, we have a \emph{data RSM} and want to estimate the NC for
the comparison to a \emph{model RSM} (i.e., 2nd level of a typical
\emph{RSA}). One would split the data set into half, generate 2
\emph{RSM}s, and correlate the off-diagonals of these \emph{RSMs}. The
resulting adjustment coefficient is the noise ceiling, but needs to be
adjusted. Therefore, we calculate

\hypertarget{references}{%
\section{References}\label{references}}

\hypertarget{refs}{}
\begin{CSLReferences}{1}{0}
\leavevmode\vadjust pre{\hypertarget{ref-carlin2017}{}}%
Carlin, Johan D., and Nikolaus Kriegeskorte. 2017. {``Adjudicating
Between Face-Coding Models with Individual-Face fMRI Responses.''}
\emph{PLOS Computational Biology} 13 (7): e1005604.
\url{https://doi.org/10.1371/journal.pcbi.1005604}.

\leavevmode\vadjust pre{\hypertarget{ref-hsu2004}{}}%
Hsu, Anne, Alexander Borst, and Frédéric E. Theunissen. 2004.
{``Quantifying variability in neural responses and its application for
the validation of model predictions.''} \emph{Network (Bristol,
England)} 15 (2): 91--109.

\leavevmode\vadjust pre{\hypertarget{ref-huth2012}{}}%
Huth, Alexander~G., Shinji Nishimoto, An~T. Vu, and Jack~L. Gallant.
2012. {``A Continuous Semantic Space Describes the Representation of
Thousands of Object and Action Categories Across the Human Brain.''}
\emph{Neuron} 76 (6): 1210--24.
\url{https://doi.org/10.1016/j.neuron.2012.10.014}.

\leavevmode\vadjust pre{\hypertarget{ref-kaniuth2022}{}}%
Kaniuth, Philipp, and Martin N. Hebart. 2022. {``Feature-Reweighted
Representational Similarity Analysis: A Method for Improving the Fit
Between Computational Models, Brains, and Behavior.''} \emph{NeuroImage}
257 (August): 119294.
\url{https://doi.org/10.1016/j.neuroimage.2022.119294}.

\leavevmode\vadjust pre{\hypertarget{ref-kriegeskorte2008}{}}%
Kriegeskorte, Nikolaus, Marieke Mur, and Peter Bandettini. 2008.
{``Representational Similarity Analysis {\textendash} Connecting the
Branches of Systems Neuroscience.''} \emph{Frontiers in Systems
Neuroscience}. \url{https://doi.org/10.3389/neuro.06.004.2008}.

\leavevmode\vadjust pre{\hypertarget{ref-lage-castellanos2019}{}}%
Lage-Castellanos, Agustin, Giancarlo Valente, Elia Formisano, and
Federico De Martino. 2019. {``Methods for Computing the Maximum
Performance of Computational Models of fMRI Responses.''} Edited by Jörn
Diedrichsen. \emph{PLOS Computational Biology} 15 (3): e1006397.
\url{https://doi.org/10.1371/journal.pcbi.1006397}.

\leavevmode\vadjust pre{\hypertarget{ref-luking2017}{}}%
Luking, Katherine R., Brady D. Nelson, Zachary P. Infantolino, Colin L.
Sauder, and Greg Hajcak. 2017. {``Internal Consistency of Functional
Magnetic Resonance Imaging and Electroencephalography Measures of Reward
in Late Childhood and Early Adolescence.''} \emph{Biological Psychiatry:
Cognitive Neuroscience and Neuroimaging} 2 (3): 289--97.
\url{https://doi.org/10.1016/j.bpsc.2016.12.004}.

\leavevmode\vadjust pre{\hypertarget{ref-nili2014}{}}%
Nili, Hamed, Cai Wingfield, Alexander Walther, Li Su, William
Marslen-Wilson, and Nikolaus Kriegeskorte. 2014. {``A Toolbox for
Representational Similarity Analysis.''} \emph{PLOS Computational
Biology} 10 (4): e1003553.
\url{https://doi.org/10.1371/journal.pcbi.1003553}.

\leavevmode\vadjust pre{\hypertarget{ref-pronk2022}{}}%
Pronk, Thomas, Dylan Molenaar, Reinout W. Wiers, and Jaap Murre. 2022.
{``Methods to Split Cognitive Task Data for Estimating Split-Half
Reliability: A Comprehensive Review and Systematic Assessment.''}
\emph{Psychonomic Bulletin \& Review} 29 (1): 44--54.
\url{https://doi.org/10.3758/s13423-021-01948-3}.

\leavevmode\vadjust pre{\hypertarget{ref-warrens2016}{}}%
Warrens, Matthijs J. 2016. {``A Comparison of Reliability Coefficients
for Psychometric Tests That Consist of Two Parts.''} \emph{Advances in
Data Analysis and Classification} 10 (1): 71--84.
\url{https://doi.org/10.1007/s11634-015-0198-6}.

\leavevmode\vadjust pre{\hypertarget{ref-xie2022}{}}%
Xie, Siying, Stefanie Hoehl, Merle Moeskops, Ezgi Kayhan, Christian
Kliesch, Bert Turtleton, Moritz Köster, and Radoslaw M. Cichy. 2022.
{``Visual Category Representations in the Infant Brain.''} \emph{Current
Biology} 32 (24): 5422--5432.e6.
\url{https://doi.org/10.1016/j.cub.2022.11.016}.

\end{CSLReferences}



\end{document}
